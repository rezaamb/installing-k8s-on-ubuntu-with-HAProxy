### ğŸš€ğŸš€ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± ÛŒÚ© Ø®ÙˆØ´Ù‡ Kubernetes Ø±ÙˆÛŒ Ubuntu Ø¨Ø§ HAProxy

Ø¨Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ÛŒÚ© Ø®ÙˆØ´Ù‡ Kubernetes Ø¨Ø§ HAProxy Ø®ÙˆØ´â€ŒØ§ÙˆÙ…Ø¯ÛŒ! Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø´Ù…Ø§ Ø±Ùˆ Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù… Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ ØªØ§ HAProxy Ø±Ùˆ ØªÙ†Ø¸ÛŒÙ… Ú©Ø±Ø¯Ù‡ Ùˆ Ø¢Ø¯Ø±Ø³ API server Ø±Ùˆ Ø¯Ø±Ø³Øª Ø¨Ù‡â€ŒÚ©Ø§Ø± Ø¨Ú¯ÛŒØ±ÛŒ.

```Tested on Ubuntu 20.04, 22.04 and 24.04 âœ…```

âœ… Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø±ÙˆÛŒ Ubuntu 20.04ØŒ 22.04 Ùˆ 24.04 ØªØ³Øª Ø´Ø¯Ù‡ Ùˆ Ù‡Ù…Ù‡ Ù…Ø±Ø§Ø­Ù„ Ø¨Ø§ Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ Ø³Ø§Ø²Ú¯Ø§Ø± Ù‡Ø³ØªÙ†Ø¯.

ğŸ“ Ù…Ù‚Ø¯Ù…Ù‡

 Ú©ÙˆØ¨Ø±Ù†ØªÛŒØ² ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ø¨Ø±Ø§ÛŒ Ø§Ø±Ú©Ø³ØªØ±ÛŒØ´Ù† Ú©Ø§Ù†ØªÛŒÙ†Ø± Ø§Ø³Øª Ú©Ù‡ Ú©Ø§Ø±Ù‡Ø§ÛŒ DeploymentØŒ Ù…Ù‚ÛŒØ§Ø³â€ŒØ¯Ù‡ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ Ø§ØªÙˆÙ…Ø§ØªÛŒÚ© Ù…ÛŒâ€ŒÚ©Ù†Ù‡. Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ØªÙˆØ³Ø· Ú¯ÙˆÚ¯Ù„ Ø´Ø±ÙˆØ¹ Ø´Ø¯ Ùˆ Ø­Ø§Ù„Ø§ Ø²ÛŒØ± Ù†Ø¸Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ùˆ Cloud Native Computing Foundation Ø§Ø¯Ø§Ù…Ù‡ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù‡.
 
Ø¨ÛŒØ§ÛŒØ¯ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ù‡ Ù…Ø±Ø­Ù„Ù‡ Ù†ØµØ¨Ø´ Ú©Ù†ÛŒÙ… âœ”ï¸


## Ø§Ù„Ù. ØºÛŒØ±ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ swap memory

 Ú©ÙˆØ¨Ø±Ù†ØªÛŒØ² Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ø±Ù‡Ø§ØŒ Ù…Ù†Ø§Ø¨Ø¹ Ø³ÛŒØ³ØªÙ… (RAM ÙˆØ§Ù‚Ø¹ÛŒ) Ø±Ùˆ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù‡. Ø§Ú¯Ø± Swap ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ù‡ØŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø®Ø±Ø§Ø¨ Ù…ÛŒâ€ŒØ´Ù‡. Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ø¨Ø§ÛŒØ¯ Ù‚Ø¨Ù„ Ø§Ø² Ù†ØµØ¨ KubernetesØŒ Swap Ø±Ùˆ Ø®Ø§Ù…ÙˆØ´ Ú©Ù†ÛŒÙ…. ÙØ§ÛŒÙ„ ```/etc/fstab``` Ø±Ùˆ Ø¨Ø§ ÙˆÛŒØ±Ø§ÛŒØ´Ú¯Ø± Ø¨Ø§Ø² Ú©Ù† Ù…Ø«Ù„ nano ÛŒØ§ vim.

ğŸ”¹ 2 Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø³Ø§Ø²ÛŒ swap Ù‡Ø³Øª:

1.1. Ø±ÙˆØ´ Ø§ÙˆÙ„:

```bash
sudo swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

1.2. Ø±ÙˆØ´ Ø¯ÙˆÙ…:
```bash
sudo vim /etc/fstab
```

Ø¯Ø§Ø®Ù„ ÙØ§ÛŒÙ„ Ø®Ø· Ù…Ø´Ø§Ø¨Ù‡ Ø²ÛŒØ± Ø±Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ù†:

```
/swapfile          none          swap          sw          0          0
```
Ùˆ Ø§ÙˆÙ† Ø®Ø· Ø±Ùˆ Ø­Ø°Ù Ú©Ù†ØŒ Ø³Ù¾Ø³ Ø³ÛŒØ³ØªÙ… Ø±Ùˆ reboot Ú©Ù†.

ğŸ’¡ Ù†Ú©ØªÙ‡:

Ø¨Ø±Ø§ÛŒ proper Ø¨ÙˆØ¯Ù† kubeletØŒ swap Ø¨Ø§ÛŒØ¯ Ø±ÙˆÛŒ Ù‡Ø± Ø¯Ùˆ Ø³Ø±ÙˆØ± Master Ùˆ Worker Ø®Ø§Ù…ÙˆØ´ Ø¨Ø´Ù‡.

2ï¸âƒ£# ØªÙ†Ø¸ÛŒÙ… IPv4 Bridge Networking Ø¯Ø± ØªÙ…Ø§Ù… Ù†ÙˆØ¯Ù‡Ø§ ğŸŒ‰

Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØªØ±Ø§ÙÛŒÚ© bridged Ø¯Ø± iptablesØŒ ÛŒÚ© Ù…Ø§Ú˜ÙˆÙ„ Ùˆ ØªÙ†Ø¸ÛŒÙ… sysctl Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ….

ğŸ”¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§:

```bash
cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF
sudo modprobe overlay
sudo modprobe br_netfilter
```

Ø§ÛŒÙ† Ø¯Ùˆ Ù…Ø§Ú˜ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ­ÛŒØ­ networking Ú©Ø§Ù†ØªÛŒÙ†Ø±Ù‡Ø§ Ø§Ù„Ø²Ø§Ù…Ù†.

ğŸ”¹ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ bridged traffic:

```bash
cat <<EOF | sudo tee /etc/sysctl.d/kubernetes.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
```

ğŸ”¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø¯ÙˆÙ† Ø±ÛŒØ¨ÙˆØª:

```bash
sudo sysctl --system
```

3ï¸âƒ£# Ù†ØµØ¨ Container Runtime (Containerd) ğŸ³


ğŸ”¹ Ù†ØµØ¨ containerd:

```bash
sudo apt install containerd -y
```

ğŸ”¹ ØªÙ†Ø¸ÛŒÙ… ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯:

```bash
sudo mkdir -p /etc/containerd
sudo containerd config default | sudo tee /etc/containerd/config.toml
```

ğŸ”¹ ÙˆÛŒØ±Ø§ÛŒØ´ ÙØ§ÛŒÙ„ Ø²ÛŒØ±:


```bash
sudo vim /etc/containerd/config.toml
```

Ø¯Ø± Ø¨Ø®Ø´ plugins... Ú¯Ø²ÛŒÙ†Ù‡ SystemdCgroup = false Ø±Ø§ Ø¨Ù‡ true ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡:

```
SystemdCgroup = true
```

ğŸ”¹ Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ ØªØºÛŒÛŒØ±Ø§Øª:

```bash
sudo systemctl restart containerd
```

4ï¸âƒ£ Ù†ØµØ¨ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Kubernetes (kubeadm, kubelet, kubectl) ğŸ› ï¸

---
Ø¨ÛŒØ§ÛŒÛŒØ¯ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ kubeletØŒ kubeadm Ùˆ kubectl Ø±Ùˆ Ø±ÙˆÛŒ Ù‡Ø± Ù†ÙˆØ¯ (Ú†Ù‡ master Ú†Ù‡ worker) Ù†ØµØ¨ Ú©Ù†ÛŒÙ… ØªØ§ Ø¨ØªÙˆÙ†ÛŒÙ… ÛŒÚ© Ø®ÙˆØ´Ù‡ (cluster) Kubernetes Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒÙ….

Ø§ÛŒÙ† Ø³Ù‡ Ù…Ø¤Ù„ÙÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ùˆ Ú©Ø§Ø± Ø¨Ø§ Ú©Ù„Ø§Ø³ØªØ± Kubernetes Ø¶Ø±ÙˆØ±ÛŒ Ù‡Ø³ØªÙ†Ø¯.
---
Ùˆ Kubeadm : Ø¯Ø³ØªÙˆØ± Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨ÙˆØªâ€ŒØ§Ø³ØªØ±Ù¾ (Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡) Ú©Ù„Ø§Ø³ØªØ±.

Ø¯Ø± ÙˆØ§Ù‚Ø¹ kubeadm Ù…Ø³Ø¦ÙˆÙ„ Ø³Ø§Ø®ØªÙ† Ú©Ù†ØªØ±Ù„ Ù¾Ù„ÛŒÙ† Ùˆ ØªÙ†Ø¸ÛŒÙ… Ø§ÙˆÙ„ÛŒÙ‡â€ŒÛŒ Ú©Ù„Ø§Ø³ØªØ± Ù‡Ø³Øª.
---
Ùˆ Kubelet : Ø³Ø±ÙˆÛŒØ³ÛŒÙ‡ Ú©Ù‡ Ø±ÙˆÛŒ ØªÙ…Ø§Ù… Ù…Ø§Ø´ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ¯ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´Ù‡ Ùˆ Ù…Ø³Ø¦ÙˆÙ„ Ø§Ø¬Ø±Ø§ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø§Ø¯Ù‡Ø§ Ùˆ Ú©Ø§Ù†ØªÛŒÙ†Ø±Ù‡Ø§ Ù‡Ø³Øª.
---
Ùˆ Kubectl : Ø§Ø¨Ø²Ø§Ø± Ø®Ø· ÙØ±Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ Ú©Ù„Ø§Ø³ØªØ±.

Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² kubectl Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ù¾Ø§Ø¯Ù‡Ø§ØŒ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ØŒ Ù†ÙˆØ¯Ù‡Ø§ Ùˆ Ø¨Ù‚ÛŒÙ‡ Ù…Ù†Ø§Ø¨Ø¹ Kubernetes Ø±Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù†ÛŒ.
---
âš ï¸ Ø§ÛŒÙ† Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ Ù…Ø®ØµÙˆØµ Ù†Ø³Ø®Ù‡â€ŒÛŒ v1.33 Ø§Ø² Kubernetes Ù‡Ø³ØªÙ†.
---

4.1 Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÛŒØ³Øª Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§:

```bash
sudo apt-get update
```
 apt-transport-https may be a dummy package; if so, you can skip that package

```bash
sudo apt-get install -y apt-transport-https ca-certificates curl gpg
```
4.2 Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ Ø§Ù…Ø¶Ø§ÛŒ Ù¾Ú©ÛŒØ¬ Kubernetes:

Ø§Ú¯Ø± Ù¾ÙˆØ´Ù‡â€ŒØ§ÛŒ Ø¨Ù‡ Ù†Ø§Ù… /etc/apt/keyrings Ø±ÙˆÛŒ Ø³ÛŒØ³ØªÙ… ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡ØŒ Ø¨Ø§ÛŒØ¯ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ± curl Ø§ÙˆÙ† Ø±Ùˆ Ø¨Ø³Ø§Ø²ÛŒ. 
```bash
sudo mkdir -p -m 755 /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.33/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
```
ğŸ’¡ ÛŒØ§Ø¯Ø¯Ø§Ø´Øª:

 Ø¯Ø± Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² Debian 12 Ùˆ Ubuntu 22.04ØŒ Ø§ÛŒÙ† Ù…Ø³ÛŒØ± /etc/apt/keyrings Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù‡.
 
Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ø¨Ø§ÛŒØ¯ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ curlØŒ Ø§ÛŒÙ† Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø±Ùˆ Ø¨Ø§ Ø¯Ø³ØªÙˆØ± mkdir Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯.

4.3 Ø§ÙØ²ÙˆØ¯Ù† Ù…Ø®Ø²Ù† Kubernetes:
```bash

# This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
```

4.4 Ù†ØµØ¨ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§:
```bash
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```
4.5 ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ kubelet:
```bash
sudo systemctl enable --now kubelet
```

The kubelet is now restarting every few seconds, as it waits in a crashloop for kubeadm to tell it what to do.
4.6 ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ kubelet:
```bash
sudo systemctl enable kubelet
```
4.7. 4.7 Ù¾ÛŒØ´â€ŒÚ©Ø´ÛŒØ¯Ù† Ø§ÛŒÙ…ÛŒØ¬â€ŒÙ‡Ø§:
```bash
sudo kubeadm config images pull
```
4.8 Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø®ÙˆØ´Ù‡ (Ø±ÙˆÛŒ Master):

ğŸ’¡ Ø§Ø¨ØªØ¯Ø§ HAProxy Ø¨Ø§ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ø¨Ø§Ø´Ù‡! â—ï¸â—ï¸â—ï¸
```bash
kubeadm init --control-plane-endpoint "apisrv.aranetco.ir:8443" --pod-network-cidr=10.244.0.0/16 --upload-certs
```
âš ï¸ Ø§Ú¯Ø± Ú©Ù„Ø§Ø³ØªØ± Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø±ÛŒØ³Øª :
```bash
sudo kubeadm reset --force
```
Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„Ø§Ø³ØªØ±ØŒ Ø¨Ø§ÛŒØ¯ kubectl Ø±Ùˆ Ø±ÙˆÛŒ Ù†ÙˆØ¯ Ù…Ø³ØªØ± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ú©Ù†ÛŒ.

Ø§ÙˆÙ„ Ø¨Ø§ÛŒØ¯ ÛŒÙ‡ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø¨Ù‡ Ø§Ø³Ù… .kube ØªÙˆÛŒ Ù¾ÙˆØ´Ù‡â€ŒÛŒ Home Ø¨Ø³Ø§Ø²ÛŒ.

Ø¨Ø¹Ø¯ØŒ ÙØ§ÛŒÙ„ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø§Ø¯Ù…ÛŒÙ† Ú©Ù„Ø§Ø³ØªØ± (Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ØªÙˆÛŒ /etc/kubernetes/admin.conf Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù‡) Ø±Ùˆ Ú©Ù¾ÛŒ Ú©Ù†ÛŒ Ø¯Ø§Ø®Ù„ Ø§ÛŒÙ† Ù¾ÙˆØ´Ù‡â€ŒÛŒ Ø´Ø®ØµÛŒ Ø®ÙˆØ¯Øª.

Ùˆ Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ù…Ø§Ù„Ú©ÛŒØª Ø§ÙˆÙ† ÙØ§ÛŒÙ„ Ø±Ùˆ Ø¨Ù‡ ÛŒÙˆØ²Ø± ÙØ¹Ù„ÛŒ Ø¨Ø¯Ù‡ ØªØ§ Ø¨ØªÙˆÙ†ÛŒ Ø¨Ø¯ÙˆÙ† sudo Ø§Ø² kubectl Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒ:


```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

Ø§Ú¯Ø± ÛŒÙˆØ²Ø± Ø±ÙˆØª Ø¨ÙˆØ¯ÛŒ:
```bash
export KUBECONFIG=/etc/kubernetes/admin.conf
```
5ï¸âƒ£# Ù†ØµØ¨ Flannel ğŸŒ

  ÛŒÚ© Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ùˆ Ø±Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ÛŒÚ© Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ù„Ø§ÛŒÙ‡ Û³ (Layer 3) Ø§Ø³Øª Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³ØªØ± Kubernetes Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡.

ğŸ”¸ ÛŒØ¹Ù†ÛŒ Ú†ÛŒØŸ Flannel Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ù†ÙˆØ¯Ù‡Ø§ Ùˆ Ù¾Ø§Ø¯Ù‡Ø§ Ø¨ØªÙˆÙ†Ù† ØªÙˆÛŒ Ú©Ù„Ø§Ø³ØªØ± Ø¨Ø§ Ù‡Ù…Ø¯ÛŒÚ¯Ù‡ Ø§Ø±ØªØ¨Ø§Ø· Ø´Ø¨Ú©Ù‡â€ŒØ§ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†ØŒ Ù…Ø®ØµÙˆØµØ§Ù‹ ÙˆÙ‚ØªÛŒ Ø§Ø² CNI (Container Network Interface) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ.

ğŸ”§ Ø¯Ø³ØªÙˆØ± Ù†ØµØ¨ Flannel:
```bash
kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
```

âš ï¸ Ù‡Ø´Ø¯Ø§Ø± Ù…Ù‡Ù…:

Ø§Ú¯Ø± Ø§Ø² ÛŒÚ© podCIDR Ø³ÙØ§Ø±Ø´ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ (ØºÛŒØ± Ø§Ø² 10.244.0.0/16)ØŒ Ø¨Ø§ÛŒØ¯ ÙØ§ÛŒÙ„ Ø¨Ø§Ù„Ø§ Ø±Ùˆ Ø§ÙˆÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒ Ùˆ Ø¨Ø¹Ø¯ Ø¯Ø§Ø®Ù„Ø´ Ù…Ù‚Ø¯Ø§Ø± Ø´Ø¨Ú©Ù‡ Ø±Ùˆ Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ podCIDR Ø®ÙˆØ¯Øª ØªØºÛŒÛŒØ± Ø¨Ø¯ÛŒ.

ÛŒØ¹Ù†ÛŒ Ú†ÛŒØŸ Ù…Ø«Ù„Ø§Ù‹ Ø§Ú¯Ù‡ Ù…ÙˆÙ‚Ø¹ kubeadm init Ø§ÛŒÙ† CIDR Ø±Ùˆ Ø¯Ø§Ø¯ÛŒ:
```bash
--pod-network-cidr=192.168.0.0/16
```
ÙˆÙ„ÛŒ Flannel Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ 10.244.0.0/16 ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ØŒ Ù¾Ø³ Ø¨Ø§ÛŒØ¯ ÙØ§ÛŒÙ„ kube-flannel.yml Ø±Ùˆ Ø¯Ø³ØªÛŒ Ø¨Ú¯ÛŒØ±ÛŒ Ùˆ ØªØºÛŒÛŒØ±Ø´ Ø¨Ø¯ÛŒ

ğŸ’¡ Ø±ÙˆØ´ Ø¯Ø±Ø³Øª:

   Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„:
```bash
curl -O https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
```

   Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ø§ ÙˆÛŒØ±Ø§ÛŒØ´Ú¯Ø±:
```bash
vim kube-flannel.yml
```
   Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ† Ø¨Ø®Ø´:
```
net-conf.json: |
  {
    "Network": "10.244.0.0/16",
    "Backend": {
      "Type": "vxlan"
    }
  }
```
ğŸ” Ùˆ ØªØºÛŒÛŒØ±Ø´ Ø¨Ù‡ Ú†ÛŒØ²ÛŒ Ù…Ø«Ù„:
```
net-conf.json: |
  {
    "Network": "192.168.0.0/16",
    "Backend": {
      "Type": "vxlan"
    }
  }
```

   Ø­Ø§Ù„Ø§ Ù†ØµØ¨:
```bash
kubectl apply -f kube-flannel.yml
```
6ï¸âƒ£# ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø®ÙˆØ¯Ú©Ø§Ø± kubectl
BASH:
```bash
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc
```
ZSH:
```bash
source <(kubectl completion zsh)
echo '[[ $commands[kubectl] ]] && source <(kubectl completion zsh)' >> ~/.zshrc
```
FISH:

For FISH shell, ensure you are using kubectl version 1.23 or above. Then, run the following command:
```bash
echo 'kubectl completion fish | source' > ~/.config/fish/completions/kubectl.fish && source ~/.config/fish/completions/kubectl.fish
```

7ï¸âƒ£# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Worker Ø¨Ù‡ Ú©Ù„Ø§Ø³ØªØ± ğŸ¤

ğŸ”¹Ø±ÙˆÛŒ Ù‡Ø± Ù†ÙˆØ¯ Worker Ø¨Ø§ÛŒØ¯ Ø¯Ø³ØªÙˆØ± kubeadm join Ø±Ùˆ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒ ØªØ§ Ø§ÛŒÙ† Ù†ÙˆØ¯ Ø¨Ù‡ Ú©Ù†ØªØ±Ù„ Ù¾Ù„ÛŒÙ† (Ù‡Ù…ÙˆÙ† Ù…Ø³ØªØ±) Ù…ØªØµÙ„ Ø¨Ø´Ù‡.
```bash
sudo kubeadm join [master-node-ip]:8443 --token [token] \
             --discovery-token-ca-cert-hash sha256:[hash]
```

ğŸš€ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡â€ŒØ¨Ù‡â€ŒÙ…Ø±Ø­Ù„Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†ÙˆØ¯ Worker:

âœ… Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§:

ğŸ›‘ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Swap

ğŸŒ‰ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ IPv4 Forwarding Ùˆ Bridge Networking

ğŸ³ Ù†ØµØ¨ Containerd (Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† runtime)

ğŸ› ï¸ ğŸ› ï¸ Ù†ØµØ¨ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú©ÙˆØ¨Ø±Ù†ØªÛŒØ² (kubeadm, kubelet, kubectl)

ğŸ”— Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ± kubeadm join Ø¨Ø±Ø§ÛŒ Ù¾ÛŒÙˆØ³ØªÙ† Ø¨Ù‡ Ú©Ù„Ø§Ø³ØªØ±

âœ… Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ù†ÙˆØ¯ Worker

ğŸŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) Ø±ÛŒâ€ŒØ¨Ø§Ù„Ø§Ù†Ø³ CoreDNS Ø§Ú¯Ø± Ø¨Ù‡â€ŒÙ‡Ù… Ø±ÛŒØ®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯

ğŸ‰ ØªØ¨Ø±ÛŒÚ©! Ù†ÙˆØ¯ Worker Ø´Ù…Ø§ Ø¨Ù‡ Ú©Ù„Ø§Ø³ØªØ± Kubernetes Ù…ØªØµÙ„ Ø´Ø¯Ù‡ !

---


8ï¸âƒ£# ØªÙ†Ø¸ÛŒÙ… HAProxy ğŸš€

ğŸ“ Ù…Ù‚Ø¯Ù…Ù‡

 Ú©Ù‡ Ù…Ø®ÙÙ Ø¹Ø¨Ø§Ø±Øª High Availability Proxy (Ù¾Ø±Ø§Ú©Ø³ÛŒ Ø¨Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³â€ŒØ¨ÙˆØ¯Ù† Ø¨Ø§Ù„Ø§) Ø§Ø³ØªØŒ
 
ÛŒÚ© Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø± Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ùˆ Ø¨Ø³ÛŒØ§Ø± Ù…Ø­Ø¨ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ù…ØªÙˆØ§Ø²Ù†â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§Ø± (Load Balancing) Ùˆ Ù¾Ø±Ø§Ú©Ø³ÛŒ Ú©Ø±Ø¯Ù† ØªØ±Ø§ÙÛŒÚ©â€ŒÙ‡Ø§ÛŒ TCP/HTTP Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.


Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±ÙˆÛŒ Ø³ÛŒØ³ØªÙ…â€ŒØ¹Ø§Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ù„ÛŒÙ†ÙˆÚ©Ø³ØŒ Ù…Ú©â€ŒØ§ÙˆØ§Ø³ Ùˆ FreeBSD Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§Ø³Øª.

Ù‡Ø¯Ù Ø§ØµÙ„ÛŒ HAProxy Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ú©Ø§Ø±Ø§ÛŒÛŒ (Performance) Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ (Reliability) Ø²ÛŒØ±Ø³Ø§Ø®Øª Ø³Ø±ÙˆØ±Ù‡Ø§ Ø±Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø¯Ù‡

Ø¨Ø§ Ù¾Ø®Ø´ Ú©Ø±Ø¯Ù† Ø¨Ø§Ø± Ú©Ø§Ø±ÛŒ Ø¨ÛŒÙ† Ú†Ù†Ø¯ÛŒÙ† Ø³Ø±ÙˆØ± Ù…Ø«Ù„ Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ ÙˆØ¨ØŒ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ÛŒØ§ Ø¯ÛŒØªØ§Ø¨ÛŒØ³.


Ùˆ HAProxy Ø¨Ù‡â€ŒØ·ÙˆØ± Ú¯Ø³ØªØ±Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ùˆ Ø´Ù†Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯

Ø§Ø² Ø¬Ù…Ù„Ù‡ Ø¯Ø± Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ Ùˆ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ GitHubØŒ ImgurØŒ Instagram Ùˆ Twitter. ğŸŒ



Ù†ØµØ¨ HAProxy:

```bash
apt install haproxy
```
ÙˆÛŒØ±Ø§ÛŒØ´ ```/etc/haproxy/haproxy.cfg:```
```bash
vim /etc/haproxy/haproxy.cfg
```
Below is the full configuration for HAProxy:

HAProxy Configuration File ğŸ› ï¸
```
# Frontend for Kubernetes API
frontend k8s-api
  bind *:8443
  mode tcp
  option tcplog
  default_backend k8s-api

# Backend for Kubernetes API
backend k8s-api
  mode tcp
  option tcplog
  option tcp-check
  balance roundrobin
  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
  server k8s-api-1 192.168.168.51:6443 check

# Monitoring HAProxy
frontend stats
  bind *:8404
  stats enable
  stats uri /stats
  stats refresh 10
```

Explanation of the Configuration File ğŸ“

1. Frontend for Kubernetes API

Ù…ÙˆØ±Ø¯ frontend k8s-api: ØªØ¹Ø±ÛŒÙ ÛŒÚ© frontend Ø¨Ù‡â€ŒÙ†Ø§Ù… k8s-api Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ø§ÙÛŒÚ© ÙˆØ±ÙˆØ¯ÛŒ.
   
 Ù…ÙˆØ±Ø¯  bind *:8443:Ø§ØªØµØ§Ù„ frontend Ø¨Ù‡ Ù¾ÙˆØ±Øª 8443 Ø±ÙˆÛŒ Ù‡Ù…Ù‡â€ŒÛŒ Ø§ÛŒÙ†ØªØ±ÙÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡â€ŒÛŒ Ø³Ø±ÙˆØ±.(ÛŒØ¹Ù†ÛŒ Ù‡Ø± ØªØ±Ø§ÙÛŒÚ©ÛŒ Ú©Ù‡ Ø¨ÛŒØ§Ø¯ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª 8443ØŒ ÙˆØ§Ø±Ø¯ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒØ´Ù‡)

 Ù…ÙˆØ±Ø¯  mode tcp:  Ø§ÛŒÙ† frontend Ø¯Ø± Ù…Ø¯ TCP (Ù„Ø§ÛŒÙ‡ 4 Ø´Ø¨Ú©Ù‡) Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù‡. Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Kubernetes API Ú©Ù‡ Ø±ÙˆÛŒ TCP Ù‡Ø³ØªØŒ Ù…Ù†Ø§Ø³Ø¨Ù‡

 Ù…ÙˆØ±Ø¯  option tcplog:  ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª TCP.
   
 Ù…ÙˆØ±Ø¯ default_backend k8s-api:  Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ú©Ù‡ Ù‡Ù…Ù‡â€ŒÛŒ ØªØ±Ø§ÙÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§ÛŒÙ† frontend Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ backend Ø¨Ù‡â€ŒÙ†Ø§Ù… k8s-api Ø§Ø±Ø³Ø§Ù„ Ø¨Ø´Ù†.

3. Backend for Kubernetes API

Ù…ÙˆØ±Ø¯ backend k8s-api: ØªØ¹Ø±ÛŒÙ ÛŒÚ© backend Ø¨Ù‡â€ŒÙ†Ø§Ù… k8s-api Ú©Ù‡ ØªØ±Ø§ÙÛŒÚ© Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² frontend Ø±Ùˆ Ù‡Ù†Ø¯Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù‡.
   
Ù…ÙˆØ±Ø¯ mode tcp: Ø§ÛŒÙ† backend Ù‡Ù… Ø¯Ø± Ù…Ø¯ TCP Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù‡.
   
Ù…ÙˆØ±Ø¯ option tcplog: ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù„Ø§Ú¯â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ TCP Ø¨Ø±Ø§ÛŒ backend.
   
Ù…ÙˆØ±Ø¯ option tcp-check: ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆØ±Ù‡Ø§ Ø¨Ø§ Ø§Ø±Ø³Ø§Ù„ TCP Ping. (health check)
   
Ù…ÙˆØ±Ø¯ balance roundrobin: Ø¨Ø§Ø± ØªØ±Ø§ÙÛŒÚ©ÛŒ Ø±Ùˆ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ú†Ø±Ø®Ø´ÛŒ (Round Robin) Ø¨ÛŒÙ† Ø³Ø±ÙˆØ±Ù‡Ø§ ØªÙˆØ²ÛŒØ¹ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
   
Ù…ÙˆØ±Ø¯ default-server: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡â€ŒÛŒ Ø³Ø±ÙˆØ±Ù‡Ø§:
   
Ù…ÙˆØ±Ø¯ inter 10s: Ù‡Ø± Û±Û° Ø«Ø§Ù†ÛŒÙ‡ ÛŒÚ©â€ŒØ¨Ø§Ø±ØŒ health check Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´Ù‡.
   
Ù…ÙˆØ±Ø¯ downinter 5s:  Ø§Ú¯Ø± Ø³Ø±ÙˆØ± down Ø¨ÙˆØ¯ØŒ health check Ù‡Ø± Ûµ Ø«Ø§Ù†ÛŒÙ‡ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´Ù‡ (Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ Ø­Ø§Ù„Øª Ø³Ø§Ù„Ù…).
   
Ù…ÙˆØ±Ø¯ rise 2: Ø³Ø±ÙˆØ± Ø¨Ø¹Ø¯ Ø§Ø² Û² Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆÙÙ‚ Ù¾Ø´Øªâ€ŒØ³Ø±â€ŒÙ‡Ù… Ø¨Ù‡ Ø­Ø§Ù„Øª Ø³Ø§Ù„Ù… (healthy) Ù…ÛŒØ±Ù‡.
   
Ù…ÙˆØ±Ø¯ fall 2: Ø³Ø±ÙˆØ± Ø¨Ø¹Ø¯ Ø§Ø² Û² Ø¨Ø§Ø± Ø´Ú©Ø³Øª Ù¾Ø´Øªâ€ŒØ³Ø±â€ŒÙ‡Ù… Ø¨Ù‡ Ø­Ø§Ù„Øª Ù†Ø§Ø³Ø§Ù„Ù… (unhealthy) Ù…ÛŒØ±Ù‡.
   
Ù…ÙˆØ±Ø¯ slowstart 60s: Ø¨Ø¹Ø¯ Ø§Ø² Ø³Ø§Ù„Ù… Ø´Ø¯Ù† Ø³Ø±ÙˆØ±ØŒ Ø·ÛŒ Û¶Û° Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ù‡â€ŒØ¢Ø±ÙˆÙ…ÛŒ ÙˆØ²Ù†Ø´ Ø§ÙØ²Ø§ÛŒØ´ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² overload Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ).
   
Ù…ÙˆØ±Ø¯ maxconn 250: Ø­Ø¯Ø§Ú©Ø«Ø± Û²ÛµÛ° Ø§Ø±ØªØ¨Ø§Ø· Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ù‡ Ù‡Ø± Ø³Ø±ÙˆØ± Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒØ´Ù‡.
   
Ù…ÙˆØ±Ø¯  maxqueue 256:Ø§Ú¯Ø± Ø³Ø±ÙˆØ± Ù¾Ø± Ø¨ÙˆØ¯ØŒ Ø­Ø¯Ø§Ú©Ø«Ø± Û²ÛµÛ¶ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± ØµÙ Ø§Ù†ØªØ¸Ø§Ø± Ù…ÛŒâ€ŒÙ…ÙˆÙ†Ù‡.
   
Ù…ÙˆØ±Ø¯ weight 100: ÙˆØ²Ù† Ø³Ø±ÙˆØ± Û±Û°Û° Ù‡Ø³ØªØŒ Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ù†Ø³Ø¨Øª Ø¨Ø§Ø± ØªØ±Ø§ÙÛŒÚ©ÛŒ (Ù…ÙˆÙ‚Ø¹ load balancing).
  
 Ù…Ø¹Ø±ÙÛŒ Ø³Ø±ÙˆØ± backend Ø¨Ù‡â€ŒÙ†Ø§Ù… k8s-api-1 Ø¨Ø§ Ø¢ÛŒâ€ŒÙ¾ÛŒ 192.168.168.51 Ú©Ù‡ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª 6443 Ú¯ÙˆØ´ Ù…ÛŒØ¯Ù‡ Ùˆ health check Ø¨Ø±Ø§Ø´ ÙØ¹Ø§Ù„Ù‡.

Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ HAProxy

Ù…ÙˆØ±Ø¯ frontend stats: ØªØ¹Ø±ÛŒÙ ÛŒÚ© frontend Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡â€ŒÙ†Ø§Ù… stats Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù¾Ù†Ù„ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ HAProxy.
    
Ù…ÙˆØ±Ø¯ bind *:8404:  Ù¾Ù†Ù„ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª 8404 Ø¯Ø± Ù‡Ù…Ù‡â€ŒÛŒ Ø§ÛŒÙ†ØªØ±ÙÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³Ù‡.
    
Ù…ÙˆØ±Ø¯ stats enable: ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ø¢Ù…Ø§Ø±ÛŒ HAProxy.
    
Ù…ÙˆØ±Ø¯ stats uri /stats:  Ø¢Ø¯Ø±Ø³ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù¾Ù†Ù„ Ø¢Ù…Ø§Ø± Ø±Ùˆ Ø±ÙˆÛŒ http://<ip>:8404/stats Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡.
    
Ù…ÙˆØ±Ø¯ stats refresh 10: Ù‡Ø± Û±Û° Ø«Ø§Ù†ÛŒÙ‡ØŒ Ø¢Ù…Ø§Ø± Ø¨Ù‡â€ŒØ±ÙˆØ² Ù…ÛŒØ´Ù‡ (auto-refresh).

9ï¸âƒ£ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¢Ø¯Ø±Ø³ API Server

When setting up your Kubernetes cluster, it is essential to ensure that the API server address is properly resolved by all machines in the cluster, including the master and worker nodes. This can be achieved in one of two ways:

ğŸŒ 1. Ú¯Ø²ÛŒÙ†Ù‡ Ø§ÙˆÙ„: DNS Ø³Ø±ÙˆØ± (Recommended)

ÛŒÚ© Ø±Ú©ÙˆØ±Ø¯ Aâ€Œ Ø¨Ø³Ø§Ø² Ú©Ù‡ Ø¢Ø¯Ø±Ø³ Ø¯Ø§Ù…Ù†Ù‡â€ŒÛŒ API Ù…Ø«Ù„ api-server.example.com Ø±Ùˆ Ø¨Ù‡ IP Ø³Ø±ÙˆØ± API Ù†Ú¯Ø§Ø´Øª Ú©Ù†Ù‡.

If you have a DNS server configured, you should add the API server's address to the DNS records. This allows all nodes and clients in the cluster to resolve the API server's domain name to its IP address automatically.

For example, you would create a DNS record that maps the API server's domain name (e.g., api-server.example.com) to its IP address (e.g., 192.168.1.50).

âœ… Advantages of Using DNS:

    Centralized domain name resolution.
    Simplifies management, especially in larger or dynamic environments.

ğŸ–¥ï¸ 2.Ú¯Ø²ÛŒÙ†Ù‡ Ø¯ÙˆÙ…: ÙØ§ÛŒÙ„ /etc/hosts

If you do not have a DNS server, you must manually configure the API server's domain name resolution by adding an entry to the /etc/hosts file on all machines associated with the Kubernetes cluster, including the master and worker nodes.
Steps to Configure /etc/hosts:

Ø±ÙˆÛŒ Ù‡Ø± Ù†ÙˆØ¯ Ø®Ø· Ø²ÛŒØ± Ø±Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†:
```bash
sudo vim /etc/hosts
```
Add the following line to map the API server's IP address to its domain name:
```
192.168.1.50 api-server.example.com
```
        Replace 192.168.1.50 with the IP address of your API server.
        Replace api-server.example.com with the desired domain name.

    Save and close the file.

â— Important Note

When you are not using a DNS server, you must include the domain name and API address of the API server in the /etc/hosts file on all machines in the Kubernetes cluster, including the master and worker nodes. This ensures that all nodes can resolve the API server's domain name to its IP address.
ğŸ“‹ Why This Step is Important

    DNS Server: Using a DNS server is the preferred method because it centralizes domain name resolution and simplifies management, especially in larger or dynamic environments.
    /etc/hosts File: This method is suitable for smaller setups or testing environments but requires manual updates on each machine if the API server's IP address changes.

ğŸ‰ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ
Ø­Ø§Ù„Ø§ HAProxy Ùˆ API Ø³Ø±ÙˆØ± Ø¨Ø§ Ù¾ÙˆØ±Øª 8443 ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù†ØŒ Kubernetes Ø¯Ø± Ù…Ø³ÛŒØ± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù‡Ø³ØªØŒ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù‡Ø³ØªÛŒ ğŸš€

ğŸŒŸ Why Use Port 8443 for HAProxy Instead of 6443 for the Kubernetes API Server?

When setting up a Kubernetes cluster with HAProxy as a load balancer, you may notice that the Kubernetes API server listens on port 6443 by default, but HAProxy is configured to listen on port 8443. This is a deliberate and important design choice. Here's why:
ğŸ”§ 1. Separation of Responsibilities

    Port 6443 is the default port used by the Kubernetes API server for secure communication.
    HAProxy acts as an intermediary (load balancer) between clients (e.g., kubectl, Kubernetes components, or external users) and the API server.
    To avoid confusion and clearly distinguish between direct API server access and load-balanced access, HAProxy is configured to listen on port 8443.

ğŸš« 2. Avoiding Port Conflicts

    If HAProxy were configured to listen on port 6443, it would conflict with the Kubernetes API server, which is already bound to that port on the master node(s).
    By using port 8443, we ensure that both services (HAProxy and the Kubernetes API server) can coexist without any port binding issues.

ğŸŒ 3. HAProxy as a Gateway

    HAProxy serves as a single entry point for all incoming traffic to the Kubernetes API server.
    By assigning it a different port (8443), it becomes clear that traffic on this port is being routed through the load balancer.
    This abstraction simplifies client configuration, as clients only need to know the HAProxy endpoint (e.g., https://haproxy.example.com:8443) rather than managing multiple API server endpoints.

ğŸ”’ 4. Security and Access Control

    Using a different port for HAProxy allows for better access control and firewall rules:
        Port 6443 can be restricted to internal components or administrators who need direct access to the API server.
        External users or clients can be directed to port 8443, where HAProxy handles load balancing and potentially additional security measures (e.g., rate limiting, logging).

âš–ï¸ 5. Flexibility in Multi-Master Setups

    In a multi-master Kubernetes cluster, HAProxy distributes traffic across multiple API servers running on different master nodes.
    By using port 8443, HAProxy provides a single, unified entry point for clients, while internally forwarding requests to the appropriate master node on port 6443.

ğŸ› ï¸ How It Works in Your Configuration

Hereâ€™s how this setup is reflected in your HAProxy configuration:

# Frontend for Kubernetes API
frontend k8s-api
  bind *:8443  # HAProxy listens on port 8443 for incoming traffic
  mode tcp
  option tcplog
  default_backend k8s-api

# Backend for Kubernetes API
backend k8s-api
  mode tcp
  option tcplog
  option tcp-check
  balance roundrobin
  server k8s-api-1 192.168.1.50:6443 check  # Forwards traffic to the API server on port 6443

    Frontend (bind *:8443): HAProxy listens for incoming traffic on port 8443.
    Backend (192.168.1.50:6443): HAProxy forwards the traffic to the Kubernetes API server running on port 6443.

This setup ensures that:

    Clients connect to HAProxy on port 8443.
    HAProxy distributes the traffic to the API server(s) on port 6443.

ğŸ¯ Key Benefits of Using Port 8443 for HAProxy

    No Port Conflicts: Avoids conflicts with the Kubernetes API server, which uses port 6443.
    Clear Separation: Distinguishes between direct API server access and load-balanced access.
    Simplified Access: Provides a single, unified entry point for clients.
    Enhanced Security: Allows for better access control and firewall rules.
    Scalability: Supports multi-master setups by routing traffic to multiple API servers.

ğŸ‰ Conclusion

Using port 8443 for HAProxy instead of port 6443 is a best practice that ensures a clean, scalable, and secure architecture for your Kubernetes cluster. It avoids conflicts, simplifies management, and provides a clear separation of responsibilities between HAProxy and the Kubernetes API server. ğŸš€
Author âœï¸
Created by Reza BND. If you find this repository helpful, feel free to fork it or contribute!
